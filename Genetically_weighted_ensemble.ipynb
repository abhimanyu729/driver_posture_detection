{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global optimization to find coefficients for weighted ensemble \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import tensordot\n",
    "from numpy.linalg import norm\n",
    "from scipy.optimize import differential_evolution\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "\n",
    "# fit model on dataset\n",
    "def fit_model(train_dir, target_x,target_y, num_epochs):\n",
    "    train_datagen = ImageDataGenerator(rescale = 1.0/255.0, rotation_range = 40, zoom_range = 0.2, \n",
    "                                  shear_range = 0.2, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                  horizontal_flip = True, fill_mode = \"nearest\")\n",
    "    train_generator = train_datagen.flow_from_directory(train_dir, target_size = (target_x,target_y), batch_size = 32, class_mode = \"categorical\")\n",
    "\n",
    "    \n",
    "    #loading pretrained model\n",
    "    # Import the inception model  \n",
    "    from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "    # Create an instance of the inception model from the local pre-trained weights\n",
    "    local_weights_file = \"Dataset/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "    pre_trained_model = InceptionV3(input_shape = (target_x,target_y,3), include_top = False, weights = None)\n",
    "    pre_trained_model.load_weights(local_weights_file)\n",
    "    \n",
    "    # Make all the layers in the pre-trained model non-trainable\n",
    "    for layer in pre_trained_model.layers:\n",
    "      layer.trainable = False\n",
    "    last_layer = pre_trained_model.get_layer('mixed9')\n",
    "    print('last layer output shape: ', last_layer.output_shape)\n",
    "    last_output = last_layer.output\n",
    "    \n",
    "    # define model\n",
    "    # Flatten the output layer to 10 dimension\n",
    "    x = layers.Flatten()(last_output)\n",
    "    # Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "    x = layers.Dense(512, activation = 'relu')(x)\n",
    "    # Add a dropout rate of 0.2  \n",
    "    # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "    x = layers.Dense(1024, activation = 'relu')(x)\n",
    "    # Add a dropout rate of 0.2\n",
    "    x = layers.Dropout(0.2)(x)                  \n",
    "    # Add a final sigmoid layer for classification\n",
    "    x = layers.Dense(10, activation = 'softmax')(x)           \n",
    "    \n",
    "    model = Model(pre_trained_model.input, x) \n",
    "    model.compile(optimizer = \"adam\", \n",
    "              loss = 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "    # fit model\n",
    "    history = model.fit(train_generator,epochs= num_epochs,verbose=1)\n",
    "    acc = history.history['accuracy'][-1]\n",
    "    return model\n",
    "\n",
    "#getting the testing data and the labels in an numpy array\n",
    "\n",
    "def get_data(dirname, img_type):\n",
    "    testX = []\n",
    "    testy = []\n",
    "    folders = os.listdir(dirname)\n",
    "    for folder in folders:\n",
    "    for image in os.listdir(os.path.join(base_path,folder)):\n",
    "        \n",
    "        img = cv2.imread(os.path.join(base_path,folder,image))\n",
    "        if img_type == 'skin':\n",
    "            #converting from gbr to YCbCr color space\n",
    "            img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "            #skin color range forYCbCr color space \n",
    "            YCrCb_mask = cv2.inRange(img_YCrCb, (0,127,77), (240,150,120)) \n",
    "            YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "            YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "            resized_image = cv2.resize(YCrCb_result, (75, 75))\n",
    "        else:\n",
    "            resized_image = cv2.resize(img, (300, 300))\n",
    "        testX.append(resized_image)\n",
    "        testy.append(folder)\n",
    "    return testX, testy\n",
    "\n",
    "    \n",
    "\n",
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(model_CNN,model_skin, weights, testX,testX_skin):\n",
    "    # make predictions\n",
    "    yhats = [model_CNN.predict(testX),model_skin.predict(testX_skin)]\n",
    "    yhats = array(yhats)\n",
    "    # weighted sum across ensemble members\n",
    "    summed = tensordot(yhats, weights, axes=((0),(0)))\n",
    "    # argmax across classes\n",
    "    result = argmax(summed, axis=1)\n",
    "    return result\n",
    "\n",
    "# # evaluate a specific number of members in an ensemble\n",
    "def evaluate_ensemble(model_CNN,model_skin, weights, testX, testy,testX_skin):\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(model_CNN,model_skin, weights, testX,testX_skin)\n",
    "    # calculate accuracy\n",
    "    return accuracy_score(testy, yhat)\n",
    "\n",
    "# normalize a vector to have unit norm\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result\n",
    "\n",
    "# loss function for optimization process, designed to be minimized\n",
    "def loss_function(weights, model_CNN,model_skin, testX, testy,testX_skin):\n",
    "    # normalize weights\n",
    "    normalized = normalize(weights)\n",
    "    # calculate error rate\n",
    "    return 1.0 - evaluate_ensemble(model_CNN,model_skin, normalized, testX, testy,testX_skin)\n",
    "\n",
    "\n",
    "\n",
    "# get test data\n",
    "\n",
    "testX, testy = get_data(\"Dataset/imgs/test\",\"normal\")\n",
    "testX_skin, _ = get_data(\"Dataset/imgs/test_skin\",\"skin\")\n",
    "testy = testy = pd.get_dummies(np.array(testy)).to_numpy()\n",
    "\n",
    "# fit all models\n",
    "model_CNN =  fit_model(\"Dataset/imgs/train\", 300,300, 15)\n",
    "model_skin =  fit_model(\"Dataset/skin_imgs\", 75,75, 50)\n",
    "\n",
    "# define bounds on each weight\n",
    "bound_w = [(0.0, 1.0)  for _ in range(2)]\n",
    "# arguments to the loss function\n",
    "search_arg = (model_CNN,model_skin, testX, testy,testX_skin)\n",
    "\n",
    "\n",
    "# global optimization of ensemble weights\n",
    "result = differential_evolution(loss_function, bound_w, search_arg, maxiter=100, tol=1e-5)\n",
    "# get the chosen weights\n",
    "# the ‘x‘ key contains the optimal set of weights found during the search.\n",
    "weights = normalize(result['x'])\n",
    "\n",
    "print('Optimized Weights: %s' % weights)\n",
    "# evaluate chosen weights\n",
    "score = evaluate_ensemble(model_CNN,model_skin, weights, testX, testy)\n",
    "\n",
    "print('Optimized Weights Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VideoCapture.open() missing required argument 'index' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-6982a166a8e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# video classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"‪D:\\videoplayback_Trim.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# capturing the video from the given path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mframeRate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#frame rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: VideoCapture.open() missing required argument 'index' (pos 1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening video stream or file\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
